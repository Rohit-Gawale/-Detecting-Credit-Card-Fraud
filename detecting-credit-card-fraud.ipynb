{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Welcome to this notebook. The goal of this notebook is to demonstrate how to handle credit card fraud datasets for ML fraud detection. Credit card fraud datasets have several specifications that make them unique and require specialized handling.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 1. Dataset Information","metadata":{}},{"cell_type":"markdown","source":"#### Context:\nThis study focuses on the identification of frauds in credit card transactions.\n\nThe dataset used here contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nCredit card companies need to detect fraudulent transactions to prevent customers from being charged for unauthorized purchases. \n\n#### Content:\n- **Dataset**: Transactions made by European cardholders in September 2013.\n- **Duration**: Two days, with 492 frauds out of 284,807 transactions.\n- **Class Imbalance**: Fraudulent transactions (positive class) account for 0.172% of all transactions.\n- **Features**:\n  - Numerical input variables resulting from PCA transformation.\n  - 'Time': Seconds elapsed between each transaction and the first transaction.\n  - 'Amount': Transaction amount, suitable for cost-sensitive learning.\n\n- **Target**:\n  - 'Class': Response variable, 1 for fraud, 0 otherwise.\n  \n#### Source:\n- The dataset has been collected and analyzed by Worldline and the Machine Learning Group (MLG) of Universit√© Libre de Bruxelles (ULB) as part of a research collaboration on big data mining and fraud detection.\n- More details on the current and past projects related to fraud detection are available on the [MLG website](http://mlg.ulb.ac.be) and [ResearchGate](https://www.researchgate.net/project/Fraud-detection-5).\n\n#### Recommendations:\n- Due to class imbalance, accuracy should be measured using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful.\n  \n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:00:58.262061Z","iopub.execute_input":"2024-07-24T15:00:58.262446Z","iopub.status.idle":"2024-07-24T15:00:59.407359Z","shell.execute_reply.started":"2024-07-24T15:00:58.262412Z","shell.execute_reply":"2024-07-24T15:00:59.405941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSV file 'creditcard.csv' into a Pandas DataFrame named df\ndf = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:01:04.009657Z","iopub.execute_input":"2024-07-24T15:01:04.010769Z","iopub.status.idle":"2024-07-24T15:01:08.211178Z","shell.execute_reply.started":"2024-07-24T15:01:04.010728Z","shell.execute_reply":"2024-07-24T15:01:08.209919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the DataFrame df\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:01:10.689588Z","iopub.execute_input":"2024-07-24T15:01:10.690026Z","iopub.status.idle":"2024-07-24T15:01:10.732444Z","shell.execute_reply.started":"2024-07-24T15:01:10.689987Z","shell.execute_reply":"2024-07-24T15:01:10.731369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a concise summary of the DataFrame df, including column names, non-null counts...\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:01:13.221496Z","iopub.execute_input":"2024-07-24T15:01:13.221912Z","iopub.status.idle":"2024-07-24T15:01:13.262532Z","shell.execute_reply.started":"2024-07-24T15:01:13.221854Z","shell.execute_reply":"2024-07-24T15:01:13.261173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no null values.","metadata":{}},{"cell_type":"code","source":"# Print the shape of the dataset (number of rows and columns)\nprint('Shape Of The Dataset', df.shape)\n\n# Print the unique class categories in the 'Class' column\nprint('Class Categories', df['Class'].unique())\n\n# Print the number of records with the class value 0 in the 'Class' column\nprint('Number Of Records With The Class Value 0: ', (df.Class == 0).sum())\n\n# Print the number of records with the class value 1 in the 'Class' column\nprint('Number Of Records With The Class Value 1: ', (df.Class == 1).sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:12:50.678123Z","iopub.execute_input":"2024-07-24T15:12:50.678553Z","iopub.status.idle":"2024-07-24T15:12:50.689186Z","shell.execute_reply.started":"2024-07-24T15:12:50.678519Z","shell.execute_reply":"2024-07-24T15:12:50.688050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a count plot to visualize the distribution of classes in the 'Class' column of the DataFrame df\nsns.countplot(x='Class', data=df)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:02:43.432410Z","iopub.execute_input":"2024-07-24T15:02:43.433130Z","iopub.status.idle":"2024-07-24T15:02:43.704741Z","shell.execute_reply.started":"2024-07-24T15:02:43.433082Z","shell.execute_reply":"2024-07-24T15:02:43.703656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    ‚ö†Ô∏è Credit card fraud datasets, including this one, are typically highly imbalanced because occurrences of fraud are rare compared to normal transactions. In the next sections, we will explore effective strategies for handling this imbalance.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 3. Features Selection","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation between the 'Class' column and the first 30 columns \nx = df.corr()['Class'][:30]\nx","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:03:19.718961Z","iopub.execute_input":"2024-07-24T15:03:19.719364Z","iopub.status.idle":"2024-07-24T15:03:20.522331Z","shell.execute_reply.started":"2024-07-24T15:03:19.719330Z","shell.execute_reply":"2024-07-24T15:03:20.520999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n**Columns meaning**\n\n1. **Time.** Time [in seconds] between this transaction and the first transaction in the dataset.\n2. **Columns V1-V28.** These are the result of a PCA dimensionality reduction. Their meaning has been made obscure intentionally because of privacy reasons.\n3. **Amount.** Transaction amount.\n4. **Class.** Type of transaction (1 for fraudulent, 0 for regular).","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation coefficients between the 'Class' column and the first 30 columns \nx = df.corr()['Class'][:30]\n\n# Create a bar plot to visualize the correlation of features with the target variable 'Class'\nx.plot.bar(figsize=(16, 9), title=\"Correlation Of Features With Target Variable\", grid=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:01.452340Z","iopub.execute_input":"2024-07-24T15:18:01.452797Z","iopub.status.idle":"2024-07-24T15:18:02.810641Z","shell.execute_reply.started":"2024-07-24T15:18:01.452758Z","shell.execute_reply":"2024-07-24T15:18:02.809495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Some features exhibit a negligible correlation with the target variable and will be removed in the subsequent sections. First, we'll examine the intercorrelation among variables.\n</div>","metadata":{}},{"cell_type":"code","source":"# Create a figure with a specific size for the heatmap\nplt.figure(figsize=(16, 9))\n\n# Create a heatmap to visualize the correlation matrix of the DataFrame df\nsns.heatmap(df.corr())","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:07.301609Z","iopub.execute_input":"2024-07-24T15:18:07.302569Z","iopub.status.idle":"2024-07-24T15:18:08.928778Z","shell.execute_reply.started":"2024-07-24T15:18:07.302531Z","shell.execute_reply":"2024-07-24T15:18:08.927601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå The only intercorrelated variable among others is the transaction Amount. However, this variable shows no correlation with the target variable, so it will also be removed.\n</div>","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation coefficients between 'Class' and all columns\ny = df.corr()['Class']\n\n# Create a copy of the DataFrame df\ndf2 = df.copy()\n\n# Iterate through columns and drop those with absolute correlation less than 0.13\nfor i in df.columns:\n    if abs(y[i]) < 0.13:\n        df2.drop(columns=[i], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:14.312984Z","iopub.execute_input":"2024-07-24T15:18:14.313713Z","iopub.status.idle":"2024-07-24T15:18:15.464409Z","shell.execute_reply.started":"2024-07-24T15:18:14.313663Z","shell.execute_reply":"2024-07-24T15:18:15.463195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìåHere, we filter our dataset to keep only features with a correlation above 0.13.\n</div>","metadata":{}},{"cell_type":"code","source":"# Display the first few rows of the DataFrame df2\ndf2.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:22.553301Z","iopub.execute_input":"2024-07-24T15:18:22.553703Z","iopub.status.idle":"2024-07-24T15:18:22.573794Z","shell.execute_reply.started":"2024-07-24T15:18:22.553672Z","shell.execute_reply":"2024-07-24T15:18:22.572506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a figure with a specific size for the heatmap\nplt.figure(figsize=(16, 9))\n\n# Create a heatmap to visualize the correlation matrix of the DataFrame df2\nsns.heatmap(df2.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:32.601518Z","iopub.execute_input":"2024-07-24T15:18:32.601966Z","iopub.status.idle":"2024-07-24T15:18:33.460422Z","shell.execute_reply.started":"2024-07-24T15:18:32.601929Z","shell.execute_reply":"2024-07-24T15:18:33.459177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation coefficients between the 'Class' column \nx = df2.corr()['Class'][:9]\n\n# Create a bar plot to visualize the top correlated features with the target variable 'Class'\nx.plot.bar(figsize=(16, 9), title=\"Top Correlated Features With The Target Variable\", grid=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:18:39.758575Z","iopub.execute_input":"2024-07-24T15:18:39.759018Z","iopub.status.idle":"2024-07-24T15:18:40.235127Z","shell.execute_reply.started":"2024-07-24T15:18:39.758982Z","shell.execute_reply":"2024-07-24T15:18:40.233942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Handling Data Imbalance","metadata":{}},{"cell_type":"markdown","source":"\n\n- This dataset consists of:\n  - Number of records with the class value 0: 284,315\n  - Number of records with the class value 1: 492\n\nUsing this dataset as it is would be a fatal mistake due to its severe class imbalance. Here's why:\n\n- **Using the data as it is:**\n  - The overwhelming majority of records belong to the non-fraudulent class (class 0), making up over 99% of the dataset.\n  - Models trained on imbalanced data may prioritize accuracy on the majority class while neglecting the minority class (fraudulent transactions). This can result in poor performance in detecting fraud.\n\n- **Why oversampling is a fatal mistake:**\n  - Oversampling techniques like SMOTE (Synthetic Minority Over-sampling Technique) artificially inflate the minority class by generating synthetic examples. However, this can lead to overfitting and the introduction of noise, especially in cases where the minority class is already sparsely represented.\n\n- **Why downsampling is the best option:**\n  - Downsampling involves randomly reducing the number of samples in the majority class to balance it with the minority class. This approach helps mitigate the biases towards the majority class while maintaining the integrity of the dataset.\n  - By reducing the number of majority class samples to match the minority class, downsampling encourages the model to learn from both classes equally, improving its ability to accurately detect fraudulent transactions.\n\n","metadata":{}},{"cell_type":"markdown","source":"\n1. **Using Imbalanced Data (No Sampling) Example:**\n   - Dataset:\n     - Class 0 (non-fraudulent transactions): 284,315 records\n     - Class 1 (fraudulent transactions): 492 records\n   - Example:\n     - Accuracy on test set: 99.8%\n     - Confusion Matrix:\n       ```\n                 Predicted Non-Fraudulent    Predicted Fraudulent\n       Actual Non-Fraudulent      71,078               200\n       Actual Fraudulent              50                40\n       ```\n     - Issue: High accuracy is misleading; the model fails to detect most fraudulent transactions (low recall for class 1).\n\n2. **Oversampling (SMOTE) Example:**\n   - Dataset:\n     - Original Class 0: 284,315 records\n     - Class 1: 492 records\n     - After SMOTE (oversampling Class 1 to match Class 0):\n       - Class 0: 284,315 records\n       - Class 1: 284,315 records (synthetic)\n   - Example:\n     - Model Performance:\n       - Accuracy: 98.5%\n       - Confusion Matrix:\n         ```\n                   Predicted Non-Fraudulent    Predicted Fraudulent\n         Actual Non-Fraudulent      70,800                  478\n         Actual Fraudulent              10                   80\n         ```\n     - Issue: High accuracy but high false positives due to synthetic examples, leading to overfitting and reduced precision for fraud detection.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Having recognized why downsampling is the optimal technique for this dataset, let's proceed with downsampling our dataset.\n</div>","metadata":{}},{"cell_type":"code","source":"\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Separate features (X) and target (y)\nX = df2.drop('Class', axis=1)\ny = df2['Class']\n\n# Initialize RandomUnderSampler\nrus = RandomUnderSampler(random_state=42)\n\n# Fit and apply the resampler to the data\nX_resampled, y_resampled = rus.fit_resample(X, y)\n\n# Convert the resampled data back to a DataFrame\ndownsampled_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=['Class'])], axis=1)\n\n\ndownsampled_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:19:04.876995Z","iopub.execute_input":"2024-07-24T15:19:04.877421Z","iopub.status.idle":"2024-07-24T15:19:04.980481Z","shell.execute_reply.started":"2024-07-24T15:19:04.877385Z","shell.execute_reply":"2024-07-24T15:19:04.979410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the shape of the downsampled DataFrame downsampled_df\ndownsampled_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:19:09.436664Z","iopub.execute_input":"2024-07-24T15:19:09.437606Z","iopub.status.idle":"2024-07-24T15:19:09.444127Z","shell.execute_reply.started":"2024-07-24T15:19:09.437569Z","shell.execute_reply":"2024-07-24T15:19:09.442943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Outliers?","metadata":{}},{"cell_type":"code","source":"# Create a count plot to visualize the distribution of classes in the 'Class' column of the downsampled DataFrame downsampled_df\nsns.countplot(x='Class', data=downsampled_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:19:16.421209Z","iopub.execute_input":"2024-07-24T15:19:16.421647Z","iopub.status.idle":"2024-07-24T15:19:16.645147Z","shell.execute_reply.started":"2024-07-24T15:19:16.421610Z","shell.execute_reply":"2024-07-24T15:19:16.644025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Now that our dataset is balanced, we can move on to the next section: handling outliers. How should we approach outliers? Should we simply delete them? Let's explore.\n</div>","metadata":{}},{"cell_type":"code","source":"# Plotting using seaborn scatterplot\nsns.scatterplot(x='V11', y='V17', hue='Class', data=df2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:19:28.940752Z","iopub.execute_input":"2024-07-24T15:19:28.941598Z","iopub.status.idle":"2024-07-24T15:19:45.441358Z","shell.execute_reply.started":"2024-07-24T15:19:28.941554Z","shell.execute_reply":"2024-07-24T15:19:45.440181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Outliers are data points that significantly deviate from the average of a variable. In other words, they do not conform to the typical grouping observed in a specific cluster. Did you notice something interesting in this plot? The blue dots represent normal transactions, tightly clustered with very few outliers. In contrast, the orange dots represent fraudulent transactions, which do not form a distinct cluster, making outlier detection challenging. Is this pattern consistent across all variables or just in this example? Let's investigate further.\n</div>","metadata":{}},{"cell_type":"code","source":"import warnings\n\n# To ignore all warnings\nwarnings.filterwarnings('ignore')\n# Pair Plot of all variables\nsns.pairplot(downsampled_df, hue='Class')","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:21:39.977344Z","iopub.execute_input":"2024-07-24T15:21:39.977806Z","iopub.status.idle":"2024-07-24T15:22:24.507591Z","shell.execute_reply.started":"2024-07-24T15:21:39.977766Z","shell.execute_reply":"2024-07-24T15:22:24.506199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå As you may have observed in this pairplot, normal transactions form a distinct cluster across all variables, whereas fraudulent transactions do not exhibit a specific cluster. This makes outlier detection extremely challenging. Attempting to manage outliers individually for each variable could result in transforming or deleting over 70% of the fraudulent transactions.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-danger\" style=\"font-size:14px; font-family:verdana;\">\n     ‚ö†Ô∏è Fraudulent transactions do not exhibit clustering behavior and do not conform to a normal distribution, making outlier identification challenging.\n    \n\n<br>- This phenomenon arises because fraud does not adhere to a typical distribution pattern; in other words, fraudulent activities vary widely and do not consistently follow specific patterns.\n\n<br>- Fraudsters employ diverse methods that evolve over time. It's important to note that simply obtaining credit card details and full names is insufficient for completing transactions. Fraudsters often employ additional techniques such as SIM swapping to bypass payment verification processes.\n\n<br>- Due to these factors, datasets containing fraudulent transactions lack distinct clustering and do not adhere to a normal distribution.\n\n<br>For these reasons, no records will be deleted from fraudulent transactions. Additionally, it's important to consider that fraudulent transactions are rare, making each record valuable. \n\n<br>Note: Outliers can still be removed from normal transactions (non-fraudulent transactions).\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## 6. Initial Exploration of Models Performance","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå To quickly assess model performance on this dataset, we will use LazyPredict for an initial evaluation of results.\n</div>","metadata":{}},{"cell_type":"code","source":"# Installation\n!pip install lazypredict","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:24:23.726127Z","iopub.execute_input":"2024-07-24T15:24:23.726582Z","iopub.status.idle":"2024-07-24T15:26:53.999706Z","shell.execute_reply.started":"2024-07-24T15:24:23.726542Z","shell.execute_reply":"2024-07-24T15:26:53.998463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom lazypredict.Supervised import LazyClassifier\n\n# Separate features and target\nx = downsampled_df.drop(columns= 'Class')\ny = downsampled_df['Class']\n\n# Split the data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\n\n# Fit all models\nclf = LazyClassifier(predictions=True)\nmodels, predictions = clf.fit(x_train, x_test, y_train, y_test)\nmodels","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:26:54.002885Z","iopub.execute_input":"2024-07-24T15:26:54.003961Z","iopub.status.idle":"2024-07-24T15:26:54.538595Z","shell.execute_reply.started":"2024-07-24T15:26:54.003911Z","shell.execute_reply":"2024-07-24T15:26:54.536664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå The top three performers are LabelSpreading, LabelPropagation, and XGBClassifier,  achieving an impressive accuracy of up to 93% to 94%. Remember these three ML algorithms as we will focus on them to construct our final model.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 7. LabelSpreading Tuning: No Improvement","metadata":{}},{"cell_type":"code","source":"from sklearn.semi_supervised import LabelSpreading\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n\n# Separate features (X) and target (y)\nX = downsampled_df.drop('Class', axis=1)\ny = downsampled_df['Class']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the LabelSpreading model\nmodel = LabelSpreading()\n\n# Define the parameter grid to search\nparam_grid = {\n    'kernel': ['knn', 'rbf'],  # Kernel function to use\n    'gamma': ['scale', 'auto', 0.1, 1.0],  # Kernel coefficient for 'rbf' and 'poly' kernels\n    'alpha': [0.1, 0.2, 0.5, 0.8],  # Clamping factor\n    'n_neighbors': [3, 5, 7]  # Number of neighbors to consider\n}\n\n# Initialize GridSearchCV with 5-fold cross-validation\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n\n# Perform grid search on the training data\ngrid_search.fit(X_train, y_train)\n\n# Get the best hyperparameters and the best score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(f\"Best Hyperparameters: {best_params}\")\nprint(f\"Best Cross-validation Accuracy: {best_score:.2f}\")\n\n# Evaluate the best model on the test set\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\n\n# Print classification report on the test set\nprint(\"\\nClassification Report on Test Set:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:26:54.539686Z","iopub.status.idle":"2024-07-24T15:26:54.540183Z","shell.execute_reply.started":"2024-07-24T15:26:54.539979Z","shell.execute_reply":"2024-07-24T15:26:54.539998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå In our effort to optimize the model's hyperparameters, the metrics remained unchanged. Let's set aside this approach and explore alternative solutions. Do you have any ideas in mind? What about the ensemble method? Let's find out!\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 8. Ensemble Voting: Major Improvement","metadata":{}},{"cell_type":"code","source":"#As previously explained, we will include the import statements in the code\n#to allow you to use or test different parts of the code separately if needed.\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.semi_supervised import LabelSpreading, LabelPropagation\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Separate features and target\nX = downsampled_df.drop(columns='Class')\ny = downsampled_df['Class']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize the models\nlabel_spreading = LabelSpreading()\nlabel_propagation = LabelPropagation()\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Create an ensemble\nensemble = VotingClassifier(estimators=[\n    ('label_spreading', label_spreading),\n    ('label_propagation', label_propagation),\n    ('xgb', xgb)\n], voting='hard')\n\n# Fit the ensemble to the training data\nensemble.fit(X_train, y_train)\n\n# Make predictions\ny_pred = ensemble.predict(X_test)\n\n# Evaluate the performance\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:26:54.541750Z","iopub.status.idle":"2024-07-24T15:26:54.542302Z","shell.execute_reply.started":"2024-07-24T15:26:54.542051Z","shell.execute_reply":"2024-07-24T15:26:54.542076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Here we go! The accuracy improved by 2%, which is quite significant. Let's see if we can further enhance the accuracy and other metrics in the next section.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 9. Enhancing the Ensemble: Tuning Parameters","metadata":{}},{"cell_type":"code","source":"#As previously explained, we will include the import statements in the code\n#to allow you to use or test different parts of the code separately if needed.\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.semi_supervised import LabelSpreading, LabelPropagation\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Separate features and target\nX = downsampled_df.drop(columns='Class')\ny = downsampled_df['Class']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize the models\nlabel_spreading = LabelSpreading()\nlabel_propagation = LabelPropagation()\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Create an ensemble\nensemble = VotingClassifier(estimators=[\n    ('label_spreading', label_spreading),\n    ('label_propagation', label_propagation),\n    ('xgb', xgb)\n], voting='hard')\n\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'label_spreading__gamma': [0.1, 0.5, 1.0, 5.0, 10.0],\n    'label_propagation__gamma': [0.1, 0.5, 1.0, 5.0, 10.0],\n    'xgb__n_estimators': [50, 100, 150],\n    'xgb__max_depth': [3, 5, 7],\n    'xgb__learning_rate': [0.01, 0.1, 0.2]\n}\n\n# Perform grid search\ngrid_search = GridSearchCV(estimator=ensemble, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=0)\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\n# Evaluate the best model on the test set\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Cross-Validation Score:\", best_score)\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:27:00.369181Z","iopub.execute_input":"2024-07-24T15:27:00.369597Z","iopub.status.idle":"2024-07-24T15:28:36.395646Z","shell.execute_reply.started":"2024-07-24T15:27:00.369562Z","shell.execute_reply":"2024-07-24T15:28:36.393883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå We didn't observe a notable improvement in metrics with the tuned parameters; nevertheless, we will retain these values for our final model.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 10. Minimizing False Negatives: A Crucial Step","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-danger\" style=\"font-size:14px; font-family:verdana;\">\n     ‚ö†Ô∏è In credit card fraud detection, minimizing false negatives (fraudulent transactions classified as non-fraudulent) is crucial and often as important as accuracy, if not more so. Classifying a fraudulent transaction as non-fraudulent can pose significant risks, potentially leading to financial losses and undermining trust in the detection system. The consequences of missing fraudulent transactions can be severe, as they may go undetected and lead to further fraudulent activities. Therefore, achieving a balance between high accuracy and low false negatives is essential for robust fraud detection systems.\n\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-danger\" style=\"font-size:14px; font-family:verdana;\">\n     ‚ö†Ô∏è Example: \n    \n\n\n- Suppose a bank earns $1 profit per transaction, whether normal or fraudulent.\n- There are 100 transactions: 99 normal and 1 fraudulent.\n- Profit from 99 normal transactions: ( 99 x \\$1 = \\$99 )\n\nNow, consider the fraudulent transaction:\n- Fraudulent transaction amount: \\$100.\n- If misclassified as normal, bank earns: \\$1.\n- Actual loss to the bank: \\$100.\n\nIn this case:\n- Bank's profit from normal transactions: \\$99.\n- Loss from misclassified fraudulent transaction: \\$100.\n\nMisclassifying the fraudulent transaction as normal means:\n- Bank's total profit calculation: \\( \\$99 + \\$1 = \\$100 \\).\n- Actual loss due to fraud: \\$100.\n\nTherefore, misclassifying one fraudulent transaction as normal would result in the bank losing all the profits earned from normal transactions, resulting in a net profit of \\$0.\n\n</div>","metadata":{}},{"cell_type":"code","source":"#As previously explained, we will include the import statements in the code\n#to allow you to use or test different parts of the code separately if needed.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.semi_supervised import LabelSpreading, LabelPropagation\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Separate features and target\nX = downsampled_df.drop(columns='Class')\ny = downsampled_df['Class']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize the models\nlabel_spreading = LabelSpreading()\nlabel_propagation = LabelPropagation()\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Create an ensemble\nensemble = VotingClassifier(estimators=[\n    ('label_spreading', label_spreading),\n    ('label_propagation', label_propagation),\n    ('xgb', xgb)\n], voting='soft')  # Use soft voting for probability output\n\n# Fit the ensemble to the training data\nensemble.fit(X_train, y_train)\n\n# Make predictions with probabilities\ny_prob = ensemble.predict_proba(X_test)[:, 1]  # Probability of being class 1 (fraud)\n\n# Adjust threshold\nthreshold = 0.26  # threshold\ny_pred_adjusted = (y_prob >= threshold).astype(int)\n\n# Evaluate the performance\nprint(\"Confusion Matrix with Adjusted Threshold:\")\nprint(confusion_matrix(y_test, y_pred_adjusted))\nprint(\"\\nClassification Report with Adjusted Threshold:\")\nprint(classification_report(y_test, y_pred_adjusted))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:28:36.399105Z","iopub.execute_input":"2024-07-24T15:28:36.400819Z","iopub.status.idle":"2024-07-24T15:28:36.737778Z","shell.execute_reply.started":"2024-07-24T15:28:36.400761Z","shell.execute_reply":"2024-07-24T15:28:36.736874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Note that in the previous model, we had FN = 8, which is quite high considering this is a fraud detection problem. In this new model, we utilized predictions with probabilities and set a threshold of 0.26. This approach reduced the FN from 8 to 3, marking a significant improvement. Moreover, this method also increased the accuracy to 97%\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 11. Adjusting Probability Thresholds for Better Detection","metadata":{}},{"cell_type":"code","source":"#As previously explained, we will include the import statements in the code\n#to allow you to use or test different parts of the code separately if needed.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.semi_supervised import LabelSpreading, LabelPropagation\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Assume downsampled_df is already loaded with features and target column\n# Separate features and target\nX = downsampled_df.drop(columns='Class')\ny = downsampled_df['Class']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize the models with best hyperparameters\nlabel_spreading = LabelSpreading(alpha=0.1, gamma=0.1, kernel='knn', n_neighbors=3)\nlabel_propagation = LabelPropagation()\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Create an ensemble with adjusted threshold\nFRAUDFIGHTER = VotingClassifier(estimators=[\n    ('label_spreading', label_spreading),\n    ('label_propagation', label_propagation),\n    ('xgb', xgb)\n], voting='soft')  # Use soft voting for probability output\n\n# Fit the ensemble to the training data\nFRAUDFIGHTER.fit(X_train, y_train)\n\n# Make predictions with probabilities\ny_prob = FRAUDFIGHTER.predict_proba(X_test)[:, 1]  # Probability of being class 1 (fraud)\n\n# Adjust threshold (e.g., 0.371)\nthreshold = 0.371\ny_pred_adjusted = (y_prob >= threshold).astype(int)\n\n# Evaluate the performance\nprint(\"Confusion Matrix with Adjusted Threshold:\")\nprint(confusion_matrix(y_test, y_pred_adjusted))\nprint(\"\\nClassification Report with Adjusted Threshold:\")\nprint(classification_report(y_test, y_pred_adjusted))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T15:28:36.745209Z","iopub.execute_input":"2024-07-24T15:28:36.749366Z","iopub.status.idle":"2024-07-24T15:28:37.094275Z","shell.execute_reply.started":"2024-07-24T15:28:36.749281Z","shell.execute_reply":"2024-07-24T15:28:37.092986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-secondary\" style=\"font-size:14px; font-family:verdana; background-color:#d3d3d3; color:#555555;\">\n    üìå Here, our final model, which incorporates the following:\n\n- Ensemble method using three algorithms: LabelSpreading, LabelPropagation, XGBClassifier.\n- Utilization of tuned hyperparameters obtained previously.\n- Introduction of a new threshold parameter for predictions with probabilities (threshold = 0.371).\n\nWe achieved a high accuracy of 97% with only 3 false negatives (FN). It's worth noting that the number of false positives (FP) in this model was also reduced from 3 to 2. The weighted average precision, recall, and F1 score all equaled 97%, demonstrating the robustness and effectiveness of this model.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 12. Conclusions ","metadata":{}},{"cell_type":"markdown","source":"\n1. **Effective Model Development:** Through meticulous data preprocessing, feature selection, and model optimization steps, we've developed a robust fraud detection model.\n   \n2. **Importance of Imbalance Handling:** Addressing the imbalance in the dataset was critical. Downsampling the majority class improved model performance by ensuring balanced representation of fraudulent and non-fraudulent transactions.\n\n3. **Model Performance:** Our final model, FRAUDFIGHTER, achieved an impressive accuracy of 97% with minimal false negatives and false positives. This underscores its capability to accurately detect fraudulent transactions.\n\n4. **Threshold Optimization:** Fine-tuning the threshold for probability predictions significantly enhanced the model's sensitivity in detecting fraudulent activities, reducing false negatives and improving overall accuracy.\n\n5. **Ensemble Approach:** Leveraging an ensemble method with carefully selected algorithms (LabelSpreading, LabelPropagation, XGBClassifier) proved effective in boosting predictive performance and robustness.\n\n6. **Real-world Application:** The methodologies and techniques applied here are crucial for real-world applications, where the cost of misclassifying fraudulent transactions can be substantial both financially and in terms of trust and customer satisfaction.\n\n7. **Future Directions:** Further enhancements could involve exploring advanced feature engineering techniques, integrating additional data sources, or deploying the model in a real-time environment to continuously improve fraud detection capabilities.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n    üìå üëã Thank you for reading this notebook! If you found this content useful, please consider giving it an upvote. Your support is greatly appreciated! üåü.\n</div>","metadata":{}}]}